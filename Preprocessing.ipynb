{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vimesh630/Automated-Image-Caption-Generator/blob/main/Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Required Libraries"
      ],
      "metadata": {
        "id": "JBCbeOE1MqDw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9_cxRu2_MVZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f821ec1-48fb-46b2-b5a9-7de60149ca1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Install any missing libraries\n",
        "!pip install nltk opencv-python pillow matplotlib\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from PIL import Image\n",
        "\n",
        "# Download NLTK data if needed\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive"
      ],
      "metadata": {
        "id": "zXheAj4eM18-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive if needed to save files or intermediate results\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nE0RDLuzM4Xf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50395e76-f6f2-42b3-96f7-eeaab8ab5d3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Up Paths & Directories"
      ],
      "metadata": {
        "id": "C2jpW-nbBR3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [2] SETUP PATHS & DIRECTORIES\n",
        "\n",
        "# Adjust these paths to match your dataset structure in Google Drive\n",
        "base_dir = '/content/drive/MyDrive/Individual projects/Automated-Caption-Generator'\n",
        "image_dir = f'{base_dir}/Images'\n",
        "caption_file = f'{base_dir}/captions.txt'\n",
        "\n",
        "# Create an output directory to store preprocessed data\n",
        "output_dir = f'{base_dir}/preprocessed'\n",
        "!mkdir -p \"{output_dir}\"\n",
        "\n",
        "print(\"Base directory:\", base_dir)\n",
        "print(\"Image directory:\", image_dir)\n",
        "print(\"Caption file:\", caption_file)\n",
        "print(\"Output directory:\", output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZXe0ELfBWfC",
        "outputId": "ce8bcca6-39ff-483a-b8b2-be30fd921b0e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base directory: /content/drive/MyDrive/Individual projects/Automated-Caption-Generator\n",
            "Image directory: /content/drive/MyDrive/Individual projects/Automated-Caption-Generator/Images\n",
            "Caption file: /content/drive/MyDrive/Individual projects/Automated-Caption-Generator/captions.txt\n",
            "Output directory: /content/drive/MyDrive/Individual projects/Automated-Caption-Generator/preprocessed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing Functions"
      ],
      "metadata": {
        "id": "DOwxZcDUM6r2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [4] PREPROCESSING FUNCTIONS\n",
        "\n",
        "# 4.1 Caption Preprocessing\n",
        "def preprocess_caption(caption):\n",
        "    \"\"\"\n",
        "    Clean and tokenize a caption.\n",
        "    \"\"\"\n",
        "    caption = caption.lower().strip()  # Lowercase and remove extra whitespace\n",
        "    caption = caption.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
        "    tokens = word_tokenize(caption)  # Tokenize into words\n",
        "    return tokens\n",
        "\n",
        "# 4.2 Load Captions\n",
        "def load_captions(caption_file_path):\n",
        "    \"\"\"\n",
        "    Load captions into a dictionary mapping image filenames to lists of tokenized captions.\n",
        "    \"\"\"\n",
        "    captions_dict = {}\n",
        "    with open(caption_file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if len(line) < 1:\n",
        "                continue\n",
        "            # Expected format: \"1000268201_693b08cb0e.jpg#0\\tA child in a pink dress...\"\n",
        "            image_caption = line.split('\\t')\n",
        "            if len(image_caption) != 2:\n",
        "                continue\n",
        "            image_info, caption = image_caption\n",
        "            # Extract image filename (remove the '#number' part)\n",
        "            image_filename = image_info.split('#')[0]\n",
        "\n",
        "            # Preprocess the caption\n",
        "            tokens = preprocess_caption(caption)\n",
        "\n",
        "            if image_filename not in captions_dict:\n",
        "                captions_dict[image_filename] = []\n",
        "            captions_dict[image_filename].append(tokens)\n",
        "    return captions_dict\n",
        "\n",
        "# 4.3 Load Image Paths\n",
        "def load_image_paths(image_directory):\n",
        "    \"\"\"\n",
        "    Load all image paths from the given directory.\n",
        "    \"\"\"\n",
        "    return [os.path.join(image_directory, img) for img in os.listdir(image_directory) if img.endswith('.jpg')]\n",
        "\n",
        "# 4.4 Preprocess Images\n",
        "def preprocess_image(image_path, target_size=(224, 224)):\n",
        "    \"\"\"\n",
        "    Preprocess an image: read, resize, and normalize pixel values.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, target_size)\n",
        "    image = image / 255.0  # Normalize pixel values to [0, 1]\n",
        "    return image"
      ],
      "metadata": {
        "id": "q8cWcIW6M9lR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Caption Preprocessing"
      ],
      "metadata": {
        "id": "P_do_CsbNADH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [5] LOAD AND PREPROCESS CAPTIONS\n",
        "\n",
        "print(\"Loading and preprocessing captions...\")\n",
        "\n",
        "captions_dict = load_captions(caption_file)\n",
        "print(f\"Total images with captions: {len(captions_dict)}\")\n",
        "\n",
        "# Save the preprocessed captions dictionary to a pickle file\n",
        "captions_output_path = os.path.join(output_dir, 'captions_dict.pkl')\n",
        "with open(captions_output_path, 'wb') as f:\n",
        "    pickle.dump(captions_dict, f)\n",
        "\n",
        "print(f\"Preprocessed captions saved to: {captions_output_path}\")"
      ],
      "metadata": {
        "id": "GotDTli0NCEy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f6f74b5-69c3-4adb-f36e-e2579b94bd38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing captions...\n",
            "Total images with captions: 0\n",
            "Preprocessed captions saved to: /content/drive/MyDrive/Individual projects/Automated-Caption-Generator/preprocessed/captions_dict.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Preprocessing"
      ],
      "metadata": {
        "id": "eUa6JGjkBn4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [6] LOAD AND PREPROCESS IMAGES\n",
        "\n",
        "print(\"Loading image paths...\")\n",
        "image_paths = load_image_paths(image_dir)\n",
        "print(f\"Total images found: {len(image_paths)}\")\n",
        "\n",
        "preprocessed_images = {}\n",
        "print(\"Preprocessing images...\")\n",
        "\n",
        "for img_path in image_paths:\n",
        "    img_filename = os.path.basename(img_path)\n",
        "    preprocessed_images[img_filename] = preprocess_image(img_path)\n",
        "\n",
        "# Save the preprocessed images dictionary\n",
        "images_output_path = os.path.join(output_dir, 'preprocessed_images.pkl')\n",
        "with open(images_output_path, 'wb') as f:\n",
        "    pickle.dump(preprocessed_images, f)\n",
        "\n",
        "print(f\"Preprocessed images saved to: {images_output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SMIybhnBpsZ",
        "outputId": "e3e8ebd7-7443-427a-b40f-a25d056c3444"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading image paths...\n",
            "Total images found: 8092\n",
            "Preprocessing images...\n",
            "Preprocessed images saved to: /content/drive/MyDrive/Individual projects/Automated-Caption-Generator/preprocessed/preprocessed_images.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize Sample Image and Caption"
      ],
      "metadata": {
        "id": "FIo58v4pNOzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [7] VISUALIZATION\n",
        "\n",
        "def display_sample_image(image_array, caption_tokens):\n",
        "    \"\"\"\n",
        "    Display a preprocessed image with its caption tokens.\n",
        "    \"\"\"\n",
        "    plt.imshow(image_array)\n",
        "    plt.title(\" \".join(caption_tokens))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Pick a sample image that has a caption\n",
        "sample_filename = list(captions_dict.keys())[0]\n",
        "sample_image = preprocessed_images[sample_filename]\n",
        "sample_caption_tokens = captions_dict[sample_filename][0]  # First caption\n",
        "\n",
        "display_sample_image(sample_image, sample_caption_tokens)"
      ],
      "metadata": {
        "id": "VrZkeSYHNT4m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "5bf62f39-48a8-4d98-8c5f-5f5ad98d2413"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-3914fd31f0f1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Pick a sample image that has a caption\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0msample_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptions_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0msample_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessed_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_filename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0msample_caption_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaptions_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_filename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# First caption\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    }
  ]
}